[["setup.html", "Section - 1 Setup and Installation 1.1 Option 1 - Run in the Cloud 1.2 Option 2 - Run Locally 1.3 Installing and Loading Packages", " Section - 1 Setup and Installation You can follow the tutorial without coding. In that case, you can move on to the next page where the tutorial actually begins. 1.1 Option 1 - Run in the Cloud If you do not currently have R and RStudio installed on your computer, you can run all of the code in a jupyter notebook using an R kernel that we have made available online in this mobile friendly link. This can take up to 30 seconds to load, and once it has you should see a page that looks like this: From here, you can run the code one cell at a time: You can also use Shift + Enter to run an individual code cell Or run all code cells at once (recommended): If you feel lost, you can do a quick interactive walkthrough under Help –&gt; User Interface Tour: 1.2 Option 2 - Run Locally If you want to follow along from your own computer directly (recommended option), please follow the installation instructions below. Afterwards, you will be able to run the code. You only need to follow these instructions once. If you have followed these steps once already, skip ahead to the next section. 1.2.1 Setup R Hopefully you already have R and RStudio installed on your computer. If you don’t have these two programs installed, you will need to: Install R. Install RStudio. This step is optional, but it is very recommended that you use an integrated development environment (IDE) like RStudio as you follow along, rather than using the R console as it was installed in step 1 above. 1.3 Installing and Loading Packages [ADD HERE] describe how to install packages, what they are, etc… like high-level version. install.packages(&#39;pacman&#39;) Load pacman: library(pacman) Install other packages: p_load(&#39;pins&#39;,&#39;tidyverse&#39;,&#39;skimr&#39;,&#39;tsibble&#39;,&#39;doParallel&#39;,&#39;DT&#39;, &#39;caret&#39;,&#39;anytime&#39;,&#39;gganimate&#39;,&#39;tictoc&#39;,&#39;gifski&#39;, &#39;xgboost&#39;,&#39;gbm&#39;,&#39;rayshader&#39;, &#39;rgl&#39;, &#39;ggthemes&#39;,&#39;ggTimeSeries&#39;, &#39;av&#39;,&#39;magick&#39;) ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;jpeg&#39;, &#39;rayimage&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpfS7Cze/downloaded_packages ## ## rayshader installed ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpfS7Cze/downloaded_packages ## ## rgl installed ## Warning in p_load(&quot;pins&quot;, &quot;tidyverse&quot;, &quot;skimr&quot;, &quot;tsibble&quot;, &quot;doParallel&quot;, : Failed to install/load: ## rayshader, rgl Nice work! Now you have everything you need to follow along with this example. "],["explore-data.html", "Section - 2 Explore the Data 2.1 Pull the Data 2.2 Data Preview 2.3 The definition of a “price” 2.4 Data Quality", " Section - 2 Explore the Data 2.1 Pull the Data The first thing we will need to do is download the latest data. We will do this by using the pins package [@R-pins], which has already been loaded into our session in the previous section. First, we will need to connect to a public GitHub repository (anyone can post their code to the GitHub website and make a “repository” with code for their project) and register the board that the data is pinned to by using the board_register() function: board_register(name = &quot;pins_board&quot;, url = &quot;https://raw.githubusercontent.com/predictcrypto/pins/master/&quot;, board = &quot;datatxt&quot;) By running the board_register() command on the URL where the data is located, we can now “ask” for the data we are interested in, which is called hitBTC_orderbook: cryptodata &lt;- pin_get(name = &quot;hitBTC_orderbook&quot;) ## | | | 0% | | | 1% | |= | 1% | |= | 2% | |== | 2% | |== | 3% | |== | 4% | |=== | 4% | |=== | 5% | |==== | 5% | |==== | 6% | |===== | 7% | |===== | 8% | |====== | 8% | |====== | 9% | |======= | 9% | |======= | 10% | |======= | 11% | |======== | 11% | |======== | 12% | |========= | 12% | |========= | 13% | |========= | 14% | |========== | 14% | |========== | 15% | |=========== | 15% | |=========== | 16% | |============ | 16% | |============ | 17% | |============ | 18% | |============= | 18% | |============= | 19% | |============== | 19% | |============== | 20% | |============== | 21% | |=============== | 21% | |=============== | 22% | |================ | 22% | |================ | 23% | |================= | 24% | |================= | 25% | |================== | 25% | |================== | 26% | |=================== | 26% | |=================== | 27% | |=================== | 28% | |==================== | 28% | |==================== | 29% | |===================== | 29% | |===================== | 30% | |===================== | 31% | |====================== | 31% | |====================== | 32% | |======================= | 32% | |======================= | 33% | |======================== | 34% | |======================== | 35% | |========================= | 35% | |========================= | 36% | |========================== | 36% | |========================== | 37% | |========================== | 38% | |=========================== | 38% | |=========================== | 39% | |============================ | 39% | |============================ | 40% | |============================ | 41% | |============================= | 41% | |============================= | 42% | |============================== | 42% | |============================== | 43% | |=============================== | 44% | |=============================== | 45% | |================================ | 45% | |================================ | 46% | |================================= | 46% | |================================= | 47% | |================================= | 48% | |================================== | 48% | |================================== | 49% | |=================================== | 49% | |=================================== | 50% | |=================================== | 51% | |==================================== | 51% | |==================================== | 52% | |===================================== | 52% | |===================================== | 53% | |===================================== | 54% | |====================================== | 54% | |====================================== | 55% | |======================================= | 55% | |======================================= | 56% | |======================================== | 56% | |======================================== | 57% | |======================================== | 58% | |========================================= | 58% | |========================================= | 59% | |========================================== | 59% | |========================================== | 60% | |========================================== | 61% | |=========================================== | 61% | |=========================================== | 62% | |============================================ | 62% | |============================================ | 63% | |============================================ | 64% | |============================================= | 64% | |============================================= | 65% | |============================================== | 65% | |============================================== | 66% | |=============================================== | 67% | |=============================================== | 68% | |================================================ | 68% | |================================================ | 69% | |================================================= | 69% | |================================================= | 70% | |================================================= | 71% | |================================================== | 71% | |================================================== | 72% | |=================================================== | 72% | |=================================================== | 73% | |=================================================== | 74% | |==================================================== | 74% | |==================================================== | 75% | |===================================================== | 75% | |===================================================== | 76% | |====================================================== | 77% | |====================================================== | 78% | |======================================================= | 78% | |======================================================= | 79% | |======================================================== | 79% | |======================================================== | 80% | |======================================================== | 81% | |========================================================= | 81% | |========================================================= | 82% | |========================================================== | 82% | |========================================================== | 83% | |========================================================== | 84% | |=========================================================== | 84% | |=========================================================== | 85% | |============================================================ | 85% | |============================================================ | 86% | |============================================================= | 87% | |============================================================= | 88% | |============================================================== | 88% | |============================================================== | 89% | |=============================================================== | 89% | |=============================================================== | 90% | |=============================================================== | 91% | |================================================================ | 91% | |================================================================ | 92% | |================================================================= | 92% | |================================================================= | 93% | |================================================================= | 94% | |================================================================== | 94% | |================================================================== | 95% | |=================================================================== | 95% | |=================================================================== | 96% | |==================================================================== | 96% | |==================================================================== | 97% | |==================================================================== | 98% | |===================================================================== | 98% | |===================================================================== | 99% | |======================================================================| 99% | |======================================================================| 100% The data has been saved to the cryptodata object. 2.2 Data Preview Below is a preview of the data: This is tidy data, meaning: Every column is a variable. Every row is an observation. Every cell is a single value. The data is collected once per hour and includes 120 days worth of data relative to today’s date. Each row is an observation of an individual cryptocurrency, and the same cryptocurrency is tracked on an hourly basis, each time presented as a new row in the dataset. Only the first 2,000 rows of the data are shown in the table above. There are 191754 rows in the actual full dataset. The latest data is from 2020-10-25. 2.3 The definition of a “price” [ADD HERE ABOUT ORDERBOOKS VS. PRICE SHOWN ON A WEBSITE] The price of a cryptocurrency on an exchange is given by the order book, where traders can post trades they want to perform. [KEEP ADDING HERE] 2.4 Data Quality First, let us get a general overview of the data to confirm there are no major data quality issues. There are several ways to do this, including using base R functions (base R meaning anything that comes with the default installation of R when you start up a new session), but we will use the skimr[@R-skimr] package to get a nicely formatted output. We can use skim() on the cryptodata dataframe to get a summary of the data to help locate any potential problems: skim(cryptodata) Table 2.1: Data summary Name cryptodata Number of rows 191754 Number of columns 27 _______________________ Column type frequency: character 5 Date 1 numeric 20 POSIXct 1 ________________________ Group variables Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace pair 0 1 5 9 0 210 0 symbol 0 1 2 6 0 210 0 quote_currency 0 1 3 3 0 1 0 pkDummy 379 1 13 13 0 1816 0 pkey 379 1 15 19 0 191095 0 Variable type: Date skim_variable n_missing complete_rate min max median n_unique date 379 1 2020-08-10 2020-10-25 2020-09-18 77 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist ask_1_price 43 1 260.81 8966.44 0 0.01 0.06 0.64 999999.0 ▇▁▁▁▁ ask_1_quantity 43 1 220144.19 5379030.21 0 18.00 423.90 3618.00 455776000.0 ▇▁▁▁▁ ask_2_price 81 1 240.07 7718.57 0 0.01 0.06 0.64 999999.0 ▇▁▁▁▁ ask_2_quantity 81 1 228387.38 4415913.99 0 20.00 444.00 5000.00 331298000.0 ▇▁▁▁▁ ask_3_price 155 1 261.16 8555.06 0 0.01 0.06 0.68 999000.0 ▇▁▁▁▁ ask_3_quantity 155 1 284465.50 4932954.60 0 14.00 400.00 7000.00 518082000.0 ▇▁▁▁▁ ask_4_price 186 1 198.57 5276.15 0 0.01 0.07 0.71 999000.0 ▇▁▁▁▁ ask_4_quantity 186 1 312637.78 5321128.54 0 12.00 418.00 7599.70 546546000.0 ▇▁▁▁▁ ask_5_price 202 1 172.79 1342.41 0 0.01 0.07 0.75 20523.8 ▇▁▁▁▁ ask_5_quantity 202 1 321090.09 5710393.12 0 12.46 433.30 8655.00 549312000.0 ▇▁▁▁▁ bid_1_price 218 1 170.06 1331.67 0 0.00 0.05 0.57 20298.0 ▇▁▁▁▁ bid_1_quantity 218 1 163467.01 2596514.57 0 30.00 666.50 7829.25 282300000.0 ▇▁▁▁▁ bid_2_price 277 1 169.89 1331.11 0 0.00 0.05 0.56 20269.5 ▇▁▁▁▁ bid_2_quantity 277 1 167825.87 3134049.54 0 20.60 480.00 6070.00 562697873.0 ▇▁▁▁▁ bid_3_price 279 1 169.56 1330.22 0 0.00 0.05 0.55 20231.5 ▇▁▁▁▁ bid_3_quantity 279 1 231257.94 3295612.82 0 12.00 373.75 6000.00 347366000.0 ▇▁▁▁▁ bid_4_price 279 1 169.18 1329.22 0 0.00 0.04 0.53 20227.4 ▇▁▁▁▁ bid_4_quantity 279 1 288697.30 3461798.77 0 10.00 380.00 7320.00 331285000.0 ▇▁▁▁▁ bid_5_price 280 1 168.63 1327.37 0 0.00 0.04 0.51 20210.4 ▇▁▁▁▁ bid_5_quantity 280 1 353310.18 4525850.83 0 10.00 380.00 8400.00 384159000.0 ▇▁▁▁▁ Variable type: POSIXct skim_variable n_missing complete_rate min max median n_unique date_time_utc 379 1 2020-08-10 04:29:09 2020-10-25 01:03:29 2020-09-18 03:02:08 177231 Move on to the next section, where we make the adjustments necessary to the data before we can start making visualizations and predictive models. "],["data-prep.html", "Section - 3 Data Prep 3.1 Remove Nulls 3.2 Calculate price_usd Column 3.3 Clean Data by Group 3.4 Any gaps? 3.5 Cross Validation 3.6 Fix Data by Split 3.7 Nest data 3.8 Functional Programming", " Section - 3 Data Prep [ADD HERE] 3.1 Remove Nulls [ADD HERE] (because we can’t do anything without ask_1_price or date_time_utc at the very least being there) Remove any rows where the ask_1_price is Null: cryptodata &lt;- cryptodata[!is.na(cryptodata$ask_1_price), ] And when the date_time_utc is Null: cryptodata &lt;- cryptodata[!is.na(cryptodata$date_time_utc), ] 3.2 Calculate price_usd Column [ADD HERE] Calculate the price_usd using the order books data and taking the cheapest price available from the ask side where at least $15 worth of the cryptocurrency are being sold. [ADD HERE] cryptodata &lt;- mutate(cryptodata, trade_usd_1 = ask_1_price * ask_1_quantity, trade_usd_2 = ask_2_price * ask_2_quantity, trade_usd_3 = ask_3_price * ask_3_quantity, trade_usd_4 = ask_4_price * ask_4_quantity, trade_usd_5 = ask_5_price * ask_5_quantity) We can look at an example [ADD HERE] head(select(cryptodata, symbol, date_time_utc, ask_1_price, ask_1_quantity, trade_usd_1)) ## [90m# A tibble: 6 x 5[39m ## symbol date_time_utc ask_1_price ask_1_quantity trade_usd_1 ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dttm&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m BTC 2020-10-25 [90m00:00:00[39m [4m1[24m[4m3[24m111. 0.31 [4m4[24m064. ## [90m2[39m ETH 2020-10-25 [90m00:00:01[39m 412. 0.4 165. ## [90m3[39m EOS 2020-10-25 [90m00:00:01[39m 2.66 600 [4m1[24m595. ## [90m4[39m LTC 2020-10-25 [90m00:00:02[39m 59.2 3.75 222. ## [90m5[39m BSV 2020-10-25 [90m00:00:03[39m 176. 0.6 106. ## [90m6[39m ADA 2020-10-25 [90m00:00:04[39m 0.108 775 83.7 If none of the top 5 orders on the order book ask side are for at least $15, exclude the row. [ADD HERE] cryptodata &lt;- mutate(cryptodata, price_usd = case_when( cryptodata$trade_usd_1 &gt;= 15 ~ cryptodata$ask_1_price, cryptodata$trade_usd_2 &gt;= 15 ~ cryptodata$ask_2_price, cryptodata$trade_usd_3 &gt;= 15 ~ cryptodata$ask_3_price, cryptodata$trade_usd_4 &gt;= 15 ~ cryptodata$ask_4_price, cryptodata$trade_usd_5 &gt;= 15 ~ cryptodata$ask_5_price)) Now remove rows where we couldn’t find a price above $15 for any of the 5 cheapest orders in the order book. cryptodata &lt;- na.omit(cryptodata) This step removed 19819 rows on the latest run. 3.3 Clean Data by Group [ADD HERE] …group_by() from the dplyr [@R-dplyr] package… cryptodata &lt;- group_by(cryptodata, symbol) 3.3.1 Remove symbols without enough rows [ADD HERE] cryptodata &lt;- dplyr::filter(cryptodata, n() &gt;= 700) The number of rows for the cryptodata dataset before the filtering step was 171556 and is now 140351. 3.3.2 Remove symbols without data from the last 3 days If there was no data collected for a cryptocurrency over the last 3 day period, let’s exclude that asset from the dataset since we are only looking to model data that is currently flowing through the process. If an asset is removed from the exchange (if a project is a scam for example) or is no longer being actively captured by the data collection process, we can’t make new predictions for it, so might as well exclude these ahead of time as well. cryptodata &lt;- dplyr::filter(cryptodata, max(date) &gt; Sys.Date()-3) The number of rows for the cryptodata dataset before this filtering step was 140351 and is now 123637. 3.4 Any gaps? [ADD HERE] 3.4.1 Convert to tsibble … the tsibble package [@R-tsibble]… 3.4.1.1 Convert to hourly data and get rid of minutes and seconds … anytime() from the anytime package [@R-anytime]… cryptodata$ts_index &lt;- anytime(paste0(cryptodata$pkDummy,&#39;:00:00&#39;)) … distinct() from the dplyr package [@R-dplyr]… cryptodata &lt;- distinct(cryptodata, symbol, ts_index, .keep_all=TRUE) … as_tsibble() from the tsibble package [@R-tsibble]… cryptodata &lt;- as_tsibble(cryptodata, index=ts_index, key=symbol) 3.4.2 Scan gaps scan_gaps(cryptodata) ## [90m# A tsibble: 40,238 x 2 [1h] &lt;UTC&gt;[39m ## [90m# Key: symbol [108][39m ## symbol ts_index ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dttm&gt;[39m[23m ## [90m 1[39m ACAT 2020-08-13 [90m22:00:00[39m ## [90m 2[39m ACAT 2020-08-14 [90m20:00:00[39m ## [90m 3[39m ACAT 2020-08-14 [90m21:00:00[39m ## [90m 4[39m ACAT 2020-08-14 [90m22:00:00[39m ## [90m 5[39m ACAT 2020-08-15 [90m01:00:00[39m ## [90m 6[39m ACAT 2020-08-15 [90m02:00:00[39m ## [90m 7[39m ACAT 2020-08-15 [90m03:00:00[39m ## [90m 8[39m ACAT 2020-08-15 [90m04:00:00[39m ## [90m 9[39m ACAT 2020-08-15 [90m05:00:00[39m ## [90m10[39m ACAT 2020-08-15 [90m06:00:00[39m ## [90m# … with 40,228 more rows[39m 3.4.3 Fill gaps cryptodata &lt;- fill_gaps(cryptodata) Now looking at the data again, there are 40238 additional rows that were added as implicitly missing in the data: cryptodata ## [90m# A tsibble: 163,688 x 34 [1h] &lt;UTC&gt;[39m ## [90m# Key: symbol [108][39m ## [90m# Groups: symbol [108][39m ## pair symbol quote_currency ask_1_price ask_1_quantity ask_2_price ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 2[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 3[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 4[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 5[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 6[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 7[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 8[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m 9[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m10[39m ACAT… ACAT USD 0.000[4m1[24m[4m9[24m [4m1[24m[4m1[24m[4m8[24m300 0.000[4m2[24m[4m2[24m ## [90m# … with 163,678 more rows, and 28 more variables: ask_2_quantity [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# ask_3_price [3m[90m&lt;dbl&gt;[90m[23m, ask_3_quantity [3m[90m&lt;dbl&gt;[90m[23m, ask_4_price [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# ask_4_quantity [3m[90m&lt;dbl&gt;[90m[23m, ask_5_price [3m[90m&lt;dbl&gt;[90m[23m, ask_5_quantity [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# bid_1_price [3m[90m&lt;dbl&gt;[90m[23m, bid_1_quantity [3m[90m&lt;dbl&gt;[90m[23m, bid_2_price [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# bid_2_quantity [3m[90m&lt;dbl&gt;[90m[23m, bid_3_price [3m[90m&lt;dbl&gt;[90m[23m, bid_3_quantity [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# bid_4_price [3m[90m&lt;dbl&gt;[90m[23m, bid_4_quantity [3m[90m&lt;dbl&gt;[90m[23m, bid_5_price [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# bid_5_quantity [3m[90m&lt;dbl&gt;[90m[23m, date_time_utc [3m[90m&lt;dttm&gt;[90m[23m, date [3m[90m&lt;date&gt;[90m[23m, pkDummy [3m[90m&lt;chr&gt;[90m[23m,[39m ## [90m# pkey [3m[90m&lt;chr&gt;[90m[23m, trade_usd_1 [3m[90m&lt;dbl&gt;[90m[23m, trade_usd_2 [3m[90m&lt;dbl&gt;[90m[23m, trade_usd_3 [3m[90m&lt;dbl&gt;[90m[23m,[39m ## [90m# trade_usd_4 [3m[90m&lt;dbl&gt;[90m[23m, trade_usd_5 [3m[90m&lt;dbl&gt;[90m[23m, price_usd [3m[90m&lt;dbl&gt;[90m[23m, ts_index [3m[90m&lt;dttm&gt;[90m[23m[39m For now, let’s convert the data back to a tibble instead of a tsibble: cryptodata &lt;- as_tibble(cryptodata) 3.4.4 Calculate Target [ADD HERE] Also adding lagged variables here! [ADD HERE] …mutate() from the dplyr [@R-dplyr] package… cryptodata &lt;- mutate(cryptodata, target_price_24h = lead(price_usd, 24, order_by=ts_index), # Now all the lagged variables: lagged_price_1h = lag(price_usd, 1, order_by=ts_index), lagged_price_2h = lag(price_usd, 2, order_by=ts_index), lagged_price_3h = lag(price_usd, 3, order_by=ts_index), lagged_price_6h = lag(price_usd, 6, order_by=ts_index), lagged_price_12h = lag(price_usd, 12, order_by=ts_index), lagged_price_24h = lag(price_usd, 24, order_by=ts_index)) #lagged_price_3d = lag(price_usd, 24*3, order_by=ts_index), #lagged_price_7d = lag(price_usd, 24*7, order_by=ts_index), #lagged_price_14d = lag(price_usd, 24*14, order_by=ts_index), #lagged_price_31d = lag(price_usd, 24*31, order_by=ts_index)) Here is an example showing the results for the subset of data related to the Ethereum cryptocurrency (using symbol == 'ETH') showing 30 rows and the relevant columns we just calculated: print(select(filter(cryptodata, symbol == &#39;ETH&#39;),ts_index, price_usd, lagged_price_1h, lagged_price_24h, target_price_24h), n=30) ## [90m# A tibble: 1,095 x 5[39m ## ts_index price_usd lagged_price_1h lagged_price_24h ## [3m[90m&lt;dttm&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m 2020-09-09 [90m11:00:00[39m 347. 5.02 [31mNA[39m ## [90m 2[39m 2020-09-09 [90m12:00:00[39m 348. 5.02 [31mNA[39m ## [90m 3[39m 2020-09-09 [90m13:00:00[39m 347. 5.01 [31mNA[39m ## [90m 4[39m 2020-09-09 [90m14:00:00[39m 348. 5.01 [31mNA[39m ## [90m 5[39m 2020-09-09 [90m15:00:00[39m 353. 5.05 [31mNA[39m ## [90m 6[39m 2020-09-09 [90m16:00:00[39m 353. 5.05 [31mNA[39m ## [90m 7[39m 2020-09-09 [90m17:00:00[39m 351. 5.05 [31mNA[39m ## [90m 8[39m 2020-09-09 [90m18:00:00[39m 352. 5.05 [31mNA[39m ## [90m 9[39m 2020-09-09 [90m19:00:00[39m 359. 5.08 [31mNA[39m ## [90m10[39m 2020-09-09 [90m20:00:00[39m 356. 5.08 [31mNA[39m ## [90m11[39m 2020-09-09 [90m21:00:00[39m 353. 5.04 171. ## [90m12[39m 2020-09-09 [90m22:00:00[39m 353. 5.01 171. ## [90m13[39m 2020-09-09 [90m23:00:00[39m 355. 5.05 172. ## [90m14[39m 2020-09-10 [90m00:00:00[39m 351. 5.02 170. ## [90m15[39m 2020-09-10 [90m01:00:00[39m 355. 5.04 170. ## [90m16[39m 2020-09-10 [90m02:00:00[39m 368. 5.11 172. ## [90m17[39m 2020-09-10 [90m03:00:00[39m 367. 5.09 172. ## [90m18[39m 2020-09-10 [90m04:00:00[39m 371. 5.09 172. ## [90m19[39m 2020-09-10 [90m05:00:00[39m 373. 5.08 171. ## [90m20[39m 2020-09-10 [90m06:00:00[39m 370. 5.08 171. ## [90m21[39m 2020-09-10 [90m07:00:00[39m 367. 5.06 170. ## [90m22[39m 2020-09-10 [90m08:00:00[39m 363. 5.05 169. ## [90m23[39m 2020-09-10 [90m09:00:00[39m 364. 5.05 169. ## [90m24[39m 2020-09-10 [90m10:00:00[39m 365. 5.07 170. ## [90m25[39m 2020-09-10 [90m11:00:00[39m 363. 5.08 169. ## [90m26[39m 2020-09-10 [90m12:00:00[39m 365. 5.12 170. ## [90m27[39m 2020-09-10 [90m13:00:00[39m 372. 5.15 170. ## [90m28[39m 2020-09-10 [90m14:00:00[39m 377. 5.16 171. ## [90m29[39m 2020-09-10 [90m15:00:00[39m 367. 5.09 169. ## [90m30[39m 2020-09-10 [90m16:00:00[39m 372. 5.12 169. ## [90m# … with 1,065 more rows, and 1 more variable: target_price_24h [3m[90m&lt;dbl&gt;[90m[23m[39m The field target_price_24h shows the value of price_usd 24 hours into the future relative to the row of data. All the lagged_ fields show the price from the past relative to when the data was collected (where lagged_price_1h shows the price 1 hour before the ts_index timestamp of the data). 3.5 Cross Validation [ADD HERE] (explain step below) NEW CV METHOD - need to explain: # Remove rows with null date_time_utc to exclude missing data from next steps cryptodata &lt;- drop_na(cryptodata, date_time_utc) # Counts by symbol cryptodata &lt;- cryptodata %&gt;% group_by(symbol) %&gt;% mutate(tot_rows = n()) # Add row index by symbol cryptodata &lt;- mutate(arrange(cryptodata, date_time_utc), row_id = seq_along(date_time_utc)) # Calculate what rows belong in the first split cryptodata &lt;- cryptodata %&gt;% mutate(split_rows_1 = as.integer(n()/5), split_rows_2 = as.integer(split_rows_1*2), split_rows_3 = as.integer(split_rows_1*3), split_rows_4 = as.integer(split_rows_1*4), split_rows_5 = as.integer(split_rows_1*5)) # Now calculate what split the current row_id belongs into cryptodata &lt;- mutate(cryptodata, split = case_when( row_id &lt;= split_rows_1 ~ 1, row_id &lt;= split_rows_2 ~ 2, row_id &lt;= split_rows_3 ~ 3, row_id &lt;= split_rows_4 ~ 4, row_id &gt; split_rows_4 ~ 5)) # Now figure out train/test groups cryptodata &lt;- cryptodata %&gt;% mutate(train_rows_1 = (as.integer(n()/5))*0.8, test_rows_1 = train_rows_1 + (as.integer(n()/5))*0.2, train_rows_2 = test_rows_1 + train_rows_1, test_rows_2 = train_rows_2 + (as.integer(n()/5))*0.2, train_rows_3 = test_rows_2 + train_rows_1, test_rows_3 = train_rows_3 + (as.integer(n()/5))*0.2, train_rows_4 = test_rows_3 + train_rows_1, test_rows_4 = train_rows_4 + (as.integer(n()/5))*0.2, train_rows_5 = test_rows_4 + train_rows_1, test_rows_5 = train_rows_5 + (as.integer(n()/5))*0.2) # Now assign train/test groups cryptodata &lt;- mutate(cryptodata, training = case_when( row_id &lt;= train_rows_1 ~ &#39;train&#39;, row_id &lt;= test_rows_1 ~ &#39;test&#39;, row_id &lt;= train_rows_2 ~ &#39;train&#39;, row_id &lt;= test_rows_2 ~ &#39;test&#39;, row_id &lt;= train_rows_3 ~ &#39;train&#39;, row_id &lt;= test_rows_3 ~ &#39;test&#39;, row_id &lt;= train_rows_4 ~ &#39;train&#39;, row_id &lt;= test_rows_4 ~ &#39;test&#39;, row_id &lt;= train_rows_5 ~ &#39;train&#39;, row_id &gt; train_rows_5 ~ &#39;holdout&#39;)) # Remove all columns that are no longer needed now cryptodata &lt;- select(cryptodata, -(tot_rows:test_rows_5), -(trade_usd_1:trade_usd_5), -(ask_1_price:bid_5_quantity), -pair, -quote_currency, -pkDummy, -pkey, -ts_index, split) Our data now has the new columns training (train, test or holdout) and split (numbers 1-5) added to it, let’s take a look at the new columns: select(cryptodata, training, split) ## Adding missing grouping variables: `symbol` ## [90m# A tibble: 123,450 x 3[39m ## [90m# Groups: symbol [108][39m ## symbol training split ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m XTZ train 1 ## [90m 2[39m BCH train 1 ## [90m 3[39m BNB train 1 ## [90m 4[39m ETC train 1 ## [90m 5[39m NEO train 1 ## [90m 6[39m LEO train 1 ## [90m 7[39m STX train 1 ## [90m 8[39m GBX train 1 ## [90m 9[39m ACT train 1 ## [90m10[39m MBL train 1 ## [90m# … with 123,440 more rows[39m Notice that even though we left symbol variables out of our selection, because it is part of the way we grouped our data, it was added back in with the message “Adding missing grouping variables symbol”. The data is tied to its groupings when performing all operations until we use ungroup() to undo them. Let’s add the new split column to the way the data is grouped: cryptodata &lt;- group_by(cryptodata, symbol, split) The new field split, helps us split the data into 5 different datasets based on the date, and contains a number from 1-5. The new field training flags the data as being part of the train dataset, or the test (or holdout for the first split) dataset for each of the 5 splits/datasets. Running the same code as before with tail() added, we should see rows associated with the test data of the 5th split (again remember, each of the 5 splits has a training and testing dataset): tail( select(cryptodata, training, split) ) ## Adding missing grouping variables: `symbol` ## [90m# A tibble: 6 x 3[39m ## [90m# Groups: symbol, split [6][39m ## symbol training split ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m1[39m VET holdout 5 ## [90m2[39m REP holdout 5 ## [90m3[39m DRT holdout 5 ## [90m4[39m DAY holdout 5 ## [90m5[39m NUT holdout 5 ## [90m6[39m UTT holdout 5 The easiest way to understand these groupings, is to visualize them. In the next section, you will learn powerful tools for visualizing data in R. Do not worry if you do not understand the code below and are not familiar with ggplot(), we will explain this framework in the next section, for now review the charts below and try to follow along with the way we are grouping the data for the predictive models by looking at what the x and y axis represent, as well as the colors. On the x-axis we are plotting the DateTime of when a data point was collected, and on the y-axis the split (1-5) as described in this section. The data is then colored based on the category assigned for the training variable (“train”,“test” or “holdout”). We can visualize the new grouping variables: groups_chart &lt;- ggplot(cryptodata, aes(x = date_time_utc, y = split, color = training)) + geom_point() #+ #scale_y_reverse() # now show the chart we just saved: groups_chart We can check on the groupings for each cryptocurrency by animating the previous chart: library(gganimate) animated_chart &lt;- groups_chart + transition_states(symbol) + ggtitle(&#39;Now showing: {closest_state}&#39;) # show the new animated chart animate(animated_chart, fps = 2) If/when need to slow these down, use this code: (can’t change fps from 1 - or at least be careful, it’s error prone) animate(animated_chart, fps = 1) This is another tool that we will walk through in the next section. It can be a bit hard to tell how many data points there are because they end up looking like lines. Let’s change the plot to use geom_jitter() instead of geom_point(), which will manually offset the points and let us see exactly how many data points there are: animated_chart &lt;- animated_chart + geom_jitter() # show the new animated chart animate(animated_chart, fps = 2) 3.6 Fix Data by Split Now that we have split the data into many different subsets, those subsets themselves may have issues that prevent the predictive models from working as expected. 3.6.1 Zero Variance One of the first models we will make is a simple linear model. The regular R function for this will not work if the data contains any columns that have “zero variance”, meaning the value of the column never changes throughout the data being given to the model. Therefore, let’s fix any issues relating to zero variance columns in any dataset before we change the structure of the data in the step after this one. First change the grouping of the data, we are interested in calculating the zero variance based on the symbol, split and training fields. cryptodata &lt;- group_by(cryptodata, symbol, split, training) Now let’s create a new object called find_zero_var which shows the value of the minimum standard deviation across all columns and calculated based on the grouping of symbol, split and train. find_zero_var &lt;- select(mutate(cryptodata, min_sd = min(sd(price_usd, na.rm=T), sd(target_price_24h, na.rm=T), sd(lagged_price_1h, na.rm=T), sd(lagged_price_2h, na.rm=T), sd(lagged_price_3h, na.rm=T), sd(lagged_price_6h, na.rm=T), sd(lagged_price_12h, na.rm=T), sd(lagged_price_24h, na.rm=T))), min_sd) ## Adding missing grouping variables: `symbol`, `split`, `training` # Show data find_zero_var ## [90m# A tibble: 123,450 x 4[39m ## [90m# Groups: symbol, split, training [1,080][39m ## symbol split training min_sd ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m XTZ 1 train 0.000[4m6[24m[4m1[24m[4m0[24m ## [90m 2[39m BCH 1 train 0.000[4m2[24m[4m8[24m[4m3[24m ## [90m 3[39m BNB 1 train 0.000[4m0[24m[4m2[24m[4m6[24m4 ## [90m 4[39m ETC 1 train 0.001[4m3[24m[4m4[24m ## [90m 5[39m NEO 1 train 0.005[4m9[24m[4m7[24m ## [90m 6[39m LEO 1 train 0.000[4m1[24m[4m0[24m[4m9[24m ## [90m 7[39m STX 1 train 0.000[4m5[24m[4m5[24m[4m3[24m ## [90m 8[39m GBX 1 train 0.001[4m1[24m[4m9[24m ## [90m 9[39m ACT 1 train 0.000[4m0[24m[4m2[24m[4m0[24m8 ## [90m10[39m MBL 1 train 0.000[4m0[24m[4m0[24m[4m6[24m67 ## [90m# … with 123,440 more rows[39m Now let’s get to a list of cryptocurrency symbols where the minimum standard deviation across all columns for all splits of the data is 0. minimum_sd &lt;- filter(distinct(mutate(group_by(ungroup(find_zero_var), symbol), min_sd = min(min_sd, na.rm=T)), min_sd),min_sd &lt; 0)$symbol ## Warning: Problem with `mutate()` input `min_sd`. ## [34mℹ[39m no non-missing arguments to min; returning Inf ## [34mℹ[39m Input `min_sd` is `min(min_sd, na.rm = T)`. ## [34mℹ[39m The error occurred in group 44: symbol = &quot;EVX&quot;. ## Warning in min(min_sd, na.rm = T): no non-missing arguments to min; returning ## Inf # Show result minimum_sd ## character(0) Now we can remove these symbols from appearing in the dataset: cryptodata &lt;- filter(cryptodata, !(symbol %in% minimum_sd)) In the code above we match all rows where the symbol is part of the minimum_sd object with the list of cryptocurrency symbols to remove from the data, and we then negate the selection using the ! operator to only keep rows with symbols not in the list we found. 3.7 Nest data [ADD HERE] … explain goal and method … First make sure groupings are correct cryptodata &lt;- group_by(cryptodata, symbol, split, training) Example nesting data: nest(cryptodata) ## [90m# A tibble: 1,080 x 4[39m ## [90m# Groups: symbol, training, split [1,080][39m ## symbol training split data ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m ## [90m 1[39m XTZ train 1 [90m&lt;tibble [176 × 10]&gt;[39m ## [90m 2[39m BCH train 1 [90m&lt;tibble [176 × 10]&gt;[39m ## [90m 3[39m BNB train 1 [90m&lt;tibble [177 × 10]&gt;[39m ## [90m 4[39m ETC train 1 [90m&lt;tibble [250 × 10]&gt;[39m ## [90m 5[39m NEO train 1 [90m&lt;tibble [177 × 10]&gt;[39m ## [90m 6[39m LEO train 1 [90m&lt;tibble [201 × 10]&gt;[39m ## [90m 7[39m STX train 1 [90m&lt;tibble [152 × 10]&gt;[39m ## [90m 8[39m GBX train 1 [90m&lt;tibble [186 × 10]&gt;[39m ## [90m 9[39m ACT train 1 [90m&lt;tibble [164 × 10]&gt;[39m ## [90m10[39m MBL train 1 [90m&lt;tibble [220 × 10]&gt;[39m ## [90m# … with 1,070 more rows[39m First make training data nested: cryptodata_train &lt;- rename(nest(filter(cryptodata, training==&#39;train&#39;)), train_data = &#39;data&#39;) # Now remove training column cryptodata_train &lt;- select(ungroup(cryptodata_train, training), -training) # Fix issues with individual groups of the data cryptodata_train$train_data &lt;- lapply(cryptodata_train$train_data, na.omit) # Remove elements with no rows after na.omit step. CONFIRM THIS WORKS!!! # First add new column with nrow of train dataset cryptodata_train &lt;- group_by(ungroup(mutate(rowwise(cryptodata_train), train_rows = nrow(train_data))), symbol, split) # Remove all symbols where their train data has less than 20 rows at least once symbols_rm &lt;- unique(filter(cryptodata_train, train_rows &lt; 20)$symbol) # Remove all data relating to the symbols found above cryptodata_train &lt;- filter(cryptodata_train, ! symbol %in% symbols_rm) # ! is to make %not in% operator # Drop train_rows column cryptodata_train &lt;- select(cryptodata_train, -train_rows) Now nest test data: cryptodata_test &lt;- select(rename(nest(filter(cryptodata, training==&#39;test&#39;)), test_data = &#39;data&#39;), -training) ## Adding missing grouping variables: `training` # Now remove training column cryptodata_test &lt;- select(ungroup(cryptodata_test, training), -training) Also do holdout: cryptodata_holdout &lt;- rename(nest(filter(cryptodata, training==&#39;holdout&#39;)), holdout_data = &#39;data&#39;) # Remove split and training columns from holdout cryptodata_holdout &lt;- select(ungroup(cryptodata_holdout, split, training), -split, -training) Now join all nested data into the same dataframe # Join train and test cryptodata_nested &lt;- left_join(cryptodata_train, cryptodata_test,by = c(&quot;symbol&quot;, &quot;split&quot;)) # Join holdout cryptodata_nested &lt;- left_join(cryptodata_nested, cryptodata_holdout, by = c(&quot;symbol&quot;)) New data: cryptodata_nested ## [90m# A tibble: 55 x 5[39m ## [90m# Groups: symbol, split [55][39m ## symbol split train_data test_data holdout_data ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m ## [90m 1[39m LINK 1 [90m&lt;tibble [45 × 10]&gt;[39m [90m&lt;tibble [50 × 10]&gt;[39m [90m&lt;tibble [52 × 10]&gt;[39m ## [90m 2[39m VET 1 [90m&lt;tibble [131 × 10]&gt;[39m [90m&lt;tibble [70 × 10]&gt;[39m [90m&lt;tibble [71 × 10]&gt;[39m ## [90m 3[39m ARPA 1 [90m&lt;tibble [59 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m [90m&lt;tibble [30 × 10]&gt;[39m ## [90m 4[39m SNT 1 [90m&lt;tibble [93 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m [90m&lt;tibble [30 × 10]&gt;[39m ## [90m 5[39m ZIL 1 [90m&lt;tibble [25 × 10]&gt;[39m [90m&lt;tibble [44 × 10]&gt;[39m [90m&lt;tibble [44 × 10]&gt;[39m ## [90m 6[39m MCO 1 [90m&lt;tibble [81 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m [90m&lt;tibble [30 × 10]&gt;[39m ## [90m 7[39m XEM 1 [90m&lt;tibble [132 × 10]&gt;[39m [90m&lt;tibble [69 × 10]&gt;[39m [90m&lt;tibble [72 × 10]&gt;[39m ## [90m 8[39m MITH 1 [90m&lt;tibble [99 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m ## [90m 9[39m COMP 1 [90m&lt;tibble [49 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m [90m&lt;tibble [29 × 10]&gt;[39m ## [90m10[39m FDZ 1 [90m&lt;tibble [195 × 10]&gt;[39m [90m&lt;tibble [51 × 10]&gt;[39m [90m&lt;tibble [54 × 10]&gt;[39m ## [90m# … with 45 more rows[39m [ADD HERE - Intro to Visualization and explain we will use grouped data in PredictiveModeling] [ADD HERE - Worth mentioning the fact that some data will be higher quality, etc…? Give more background on those steps as “catch-alls”?] 3.8 Functional Programming Could work with the data using for loops, which is an “object-oriented” approach. Basically, we could take our given option, iterate through every row of the data, and perform operations on each row and subset of the data we are interested in. That is one approach, but instead we will use a different approach using a “functional programming” approach –&gt; "],["visualization.html", "Section - 4 Visualization 📉 4.1 Basics - ggplot2 4.2 Using Extensions", " Section - 4 Visualization 📉 Making visualizations using ggplot2 is one of the very best tools available in the R ecosystem. The gg in ggplot2 stands for the Grammar of Graphics, which is essentially the idea that many different types of charts share the same underlying building blocks, and that they can be put together in different ways to make charts that look very different from each other. In Hadley’s own words, “a pie chart is just a bar chart drawn in polar coordinates”, “They look very different, but in terms of the grammar they have a lot of underlying similarities.” 4.1 Basics - ggplot2 So how does ggplot2 actually work? “…in most cases you start with ggplot(), supply a dataset and aesthetic mapping (with aes()). You then add on layers (like geom_point() or geom_histogram()), scales (like scale_colour_brewer()), faceting specifications (like facet_wrap()) and coordinate systems (like coord_flip()).” - ggplot2.tidyverse.org/. Let’s break this down step by step. \"start with ggplot(), supply a dataset and aesthetic mapping (with aes()) ggplot(data = cryptodata, aes(x = date_time_utc, y = price_usd)) The chart now shows up but is blank because we need to perform an additional step “You then add on layers (like geom_point() or geom_histogram())…” We can take the exact same code as above and add + geom_point() ggplot(data = cryptodata, aes(x = date_time_utc, y = price_usd)) + # adding geom_point(): geom_point() The most expensive cryptocurrency being shown, BTC in this case, makes it difficult to take a look at any of the other ones. Let’s try zooming-in on a single one by using the same code but making an adjustment to the data parameter to only show data for the cryptocurrency with the symbol ETH, first let’s filter the data down to those results only: eth_data &lt;- subset(cryptodata, symbol == &#39;ETH&#39;) ggplot(data = eth_data, aes(x = date_time_utc, y = price_usd)) + geom_point() The axis automatically adjusted to the new data. This is better, but geom_point() might not be the best choice for this chart, let’s change geom_point with geom_line and see what that looks like: ggplot(data = eth_data, aes(x = date_time_utc, y = price_usd)) + # changing geom_point() into geom_line(): geom_line() Let’s save the results as an object called crypto_chart: crypto_chart &lt;- ggplot(data = eth_data, aes(x = date_time_utc, y = price_usd)) + geom_line() We can add a linear regression line going through the plot to show the strength of the relationship between the two values. A horizontal line would show a weak relationship, while a sloped line would show a strong one. crypto_chart &lt;- crypto_chart + stat_smooth(method = &#39;lm&#39;) crypto_chart ## `geom_smooth()` using formula &#39;y ~ x&#39; Next, let’s adjust the labels on the chart: crypto_chart &lt;- crypto_chart + ggtitle(&#39;Previous 24h % Price Change Vs. Next 24h Price % Change&#39;, subtitle = max(eth_data$symbol)) + xlab(&#39;Previous 24 hours % Price Change&#39;) + ylab(&#39;Next 24 hours % Price Change&#39;) # display the new chart crypto_chart ## `geom_smooth()` using formula &#39;y ~ x&#39; 4.2 Using Extensions 4.2.1 ggthemes Let’s import a ggplot2 “extension” by importing a package called ggthemes [@R-ggthemes] and apply a theme to change the overall look of the chart: # apply the theme &quot;economist&quot; crypto_chart &lt;- crypto_chart + theme_economist() # display the new chart crypto_chart You can find a full list of themes here: https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/ 4.2.2 plotly In some cases, it’s helpful to make a chart responsive to a cursor hovering over it. We can convert any ggplot into an interactive chart by using the plotly [@R-plotly] package: If you are not looking to convert a ggplot, plotly also provides its own framework for making charts available in R, you can find out more about it here: https://plotly.com/r/ 4.2.3 gganimate We can repeat the same steps on the complete dataset, and then animate the results for each of the groups. Here is the first chart again, animated based on the groupings we created in the previous section: animated_prices &lt;- ggplot(data = mutate(cryptodata, groups=symbol), aes(x = date_time_utc, y = price_usd)) + geom_point() + transition_states(groups) + ggtitle(&#39;Price Over Time&#39;,subtitle = &#39;{closest_state}&#39;) + view_follow() # this adjusts the axis based on the group # Show animation: animated_prices We can slow down the animation by using animate() and choosing the speed in terms of the frames per second (fps)\" animated_prices_result &lt;- animate(animated_prices,fps=1) # show slowed down results animated_prices_result 4.2.4 Calendar Heatmap For this kind of timeseries data, another nice view we can take of the data is a calendar heatmap, by using the package ggTimeSeries [@R-ggTimeSeries]: calendar_heatmap &lt;- ggplot_calendar_heatmap(eth_data,&#39;date_time_utc&#39;,&#39;price_usd&#39;) #or do target_percent_change here? calendar_heatmap DoW on the y-axis stands for Day Of the Week 4.2.5 Rayshader Awesome! Move on to the next section to start making predictive models for the data, or keep reading below to learn more about ggplot2 extensions. "],["predictive-modeling.html", "Section - 5 Predictive Modeling 5.1 Example Simple Model 5.2 Caret 5.3 Make Predictions 5.4 Traditional Timeseries", " Section - 5 Predictive Modeling 5.1 Example Simple Model …First need to run example normal lm model, etc… 5.1.1 Using Functional Programming linear_model &lt;- function(df){ lm(price_usd ~ . -date_time_utc -date, data = df) } Can now use it for map() cryptodata_nested %&gt;% mutate(lm_model = map(train_data, linear_model)) ## [90m# A tibble: 55 x 6[39m ## [90m# Groups: symbol, split [55][39m ## symbol split train_data test_data holdout_data lm_model ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m ## [90m 1[39m LINK 1 [90m&lt;tibble [45 × 10]&gt;[39m [90m&lt;tibble [50 × 10[0m… [90m&lt;tibble [52 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 2[39m VET 1 [90m&lt;tibble [131 × 10]&gt;[39m [90m&lt;tibble [70 × 10[0m… [90m&lt;tibble [71 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 3[39m ARPA 1 [90m&lt;tibble [59 × 10]&gt;[39m [90m&lt;tibble [29 × 10[0m… [90m&lt;tibble [30 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 4[39m SNT 1 [90m&lt;tibble [93 × 10]&gt;[39m [90m&lt;tibble [29 × 10[0m… [90m&lt;tibble [30 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 5[39m ZIL 1 [90m&lt;tibble [25 × 10]&gt;[39m [90m&lt;tibble [44 × 10[0m… [90m&lt;tibble [44 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 6[39m MCO 1 [90m&lt;tibble [81 × 10]&gt;[39m [90m&lt;tibble [29 × 10[0m… [90m&lt;tibble [30 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 7[39m XEM 1 [90m&lt;tibble [132 × 10]&gt;[39m [90m&lt;tibble [69 × 10[0m… [90m&lt;tibble [72 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 8[39m MITH 1 [90m&lt;tibble [99 × 10]&gt;[39m [90m&lt;tibble [29 × 10[0m… [90m&lt;tibble [29 × 10[0m… [90m&lt;lm&gt;[39m ## [90m 9[39m COMP 1 [90m&lt;tibble [49 × 10]&gt;[39m [90m&lt;tibble [29 × 10[0m… [90m&lt;tibble [29 × 10[0m… [90m&lt;lm&gt;[39m ## [90m10[39m FDZ 1 [90m&lt;tibble [195 × 10]&gt;[39m [90m&lt;tibble [51 × 10[0m… [90m&lt;tibble [54 × 10[0m… [90m&lt;lm&gt;[39m ## [90m# … with 45 more rows[39m 5.2 Caret 5.2.1 Parallel Processing [ADD HERE About R only using one CPU as deafault but can use more enabling parallel processing] library(doParallel) cl &lt;- makePSOCKcluster(12) registerDoParallel(cl) 5.2.2 Functional Programming - here or elsewhere? [ADD HERE] Here use Caret + purrr to make models linear_model_caret &lt;- function(df){ train(price_usd ~ . -date_time_utc -date, data = df, method = &#39;lm&#39;, trControl=trainControl(method=&quot;none&quot;)) } Can now use it for map() cryptodata_nested &lt;- mutate(cryptodata_nested, lm_model = map(train_data, linear_model_caret)) 5.2.3 Cross Validation Within each split we created, we can set caret to perform an additional cross-validation step to allow it to do a minimal level of automated hyperparameter tuning as it creates the models (the more we do the longer it will take). fitControl &lt;- trainControl(## 3-fold CV method = &quot;repeatedcv&quot;, number = 3, ## repeated three times repeats = 3) Now create more generalized version model_caret &lt;- function(df, method_choice){ train(price_usd ~ . -date_time_utc -date, data = df, method = method_choice, trControl=fitControl) } 5.2.4 XGBoost models Will now need to use map2() cryptodata_nested &lt;- mutate(cryptodata_nested, xgb_model = map2(train_data, &quot;xgbLinear&quot;,model_caret)) ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 1: symbol = &quot;ARPA&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 2: symbol = &quot;ARPA&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 4: symbol = &quot;ARPA&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 5: symbol = &quot;ARPA&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 6: symbol = &quot;COCOS&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 7: symbol = &quot;COCOS&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 8: symbol = &quot;COCOS&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 9: symbol = &quot;COCOS&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 10: symbol = &quot;COCOS&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 16: symbol = &quot;FDZ&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 17: symbol = &quot;FDZ&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 18: symbol = &quot;FDZ&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 19: symbol = &quot;FDZ&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 31: symbol = &quot;MITH&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 32: symbol = &quot;MITH&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 33: symbol = &quot;MITH&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 34: symbol = &quot;MITH&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 35: symbol = &quot;MITH&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 36: symbol = &quot;SNT&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 38: symbol = &quot;SNT&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 41: symbol = &quot;VET&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 44: symbol = &quot;VET&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 45: symbol = &quot;VET&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 48: symbol = &quot;XEM&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 51: symbol = &quot;ZIL&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 52: symbol = &quot;ZIL&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 54: symbol = &quot;ZIL&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgb_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgb_model` is `map2(train_data, &quot;xgbLinear&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 55: symbol = &quot;ZIL&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. Can also make a tree based XGBoost model: cryptodata_nested &lt;- mutate(cryptodata_nested, xgbTree_model = map2(train_data, &quot;xgbTree&quot;,model_caret)) ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 2: symbol = &quot;ARPA&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 4: symbol = &quot;ARPA&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 6: symbol = &quot;COCOS&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 7: symbol = &quot;COCOS&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 8: symbol = &quot;COCOS&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 9: symbol = &quot;COCOS&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 10: symbol = &quot;COCOS&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 16: symbol = &quot;FDZ&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 17: symbol = &quot;FDZ&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 18: symbol = &quot;FDZ&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 19: symbol = &quot;FDZ&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `xgbTree_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `xgbTree_model` is `map2(train_data, &quot;xgbTree&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 45: symbol = &quot;VET&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. [TODO - Reference xgboost documentation. Can I embed it? https://xgboost.readthedocs.io/en/latest/parameter.html] 5.2.5 All Other Models Can use the same function and methodology to keep adding models. Could also all be done in one step adding more arguments to mutate(), but broken up to be verbose and take it step by step. 5.2.5.1 Neural Network models cryptodata_nested &lt;- mutate(cryptodata_nested, nnet_model = map2(train_data, &quot;dnn&quot;, model_caret)) ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 1: symbol = &quot;ARPA&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 1: symbol = &quot;ARPA&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 2: symbol = &quot;ARPA&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 2: symbol = &quot;ARPA&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 3: symbol = &quot;ARPA&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 3: symbol = &quot;ARPA&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 4: symbol = &quot;ARPA&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 4: symbol = &quot;ARPA&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 5: symbol = &quot;ARPA&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 5: symbol = &quot;ARPA&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 6: symbol = &quot;COCOS&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 6: symbol = &quot;COCOS&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 7: symbol = &quot;COCOS&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 7: symbol = &quot;COCOS&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 8: symbol = &quot;COCOS&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 8: symbol = &quot;COCOS&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 9: symbol = &quot;COCOS&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 9: symbol = &quot;COCOS&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 9: symbol = &quot;COCOS&quot;, split = 4. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 10: symbol = &quot;COCOS&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 10: symbol = &quot;COCOS&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 11: symbol = &quot;COMP&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 11: symbol = &quot;COMP&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 11: symbol = &quot;COMP&quot;, split = 1. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 12: symbol = &quot;COMP&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 12: symbol = &quot;COMP&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 13: symbol = &quot;COMP&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 13: symbol = &quot;COMP&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 14: symbol = &quot;COMP&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 14: symbol = &quot;COMP&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 15: symbol = &quot;COMP&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 15: symbol = &quot;COMP&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 16: symbol = &quot;FDZ&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 16: symbol = &quot;FDZ&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 16: symbol = &quot;FDZ&quot;, split = 1. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 17: symbol = &quot;FDZ&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 17: symbol = &quot;FDZ&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 17: symbol = &quot;FDZ&quot;, split = 2. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 18: symbol = &quot;FDZ&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 18: symbol = &quot;FDZ&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 19: symbol = &quot;FDZ&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 19: symbol = &quot;FDZ&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 21: symbol = &quot;LINK&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 21: symbol = &quot;LINK&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 22: symbol = &quot;LINK&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 22: symbol = &quot;LINK&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 23: symbol = &quot;LINK&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 23: symbol = &quot;LINK&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 24: symbol = &quot;LINK&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 24: symbol = &quot;LINK&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 25: symbol = &quot;LINK&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 25: symbol = &quot;LINK&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 26: symbol = &quot;MCO&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 26: symbol = &quot;MCO&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 27: symbol = &quot;MCO&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 27: symbol = &quot;MCO&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 28: symbol = &quot;MCO&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 28: symbol = &quot;MCO&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 28: symbol = &quot;MCO&quot;, split = 3. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 29: symbol = &quot;MCO&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 29: symbol = &quot;MCO&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 30: symbol = &quot;MCO&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 30: symbol = &quot;MCO&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 31: symbol = &quot;MITH&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 31: symbol = &quot;MITH&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 32: symbol = &quot;MITH&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 32: symbol = &quot;MITH&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 33: symbol = &quot;MITH&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 33: symbol = &quot;MITH&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 33: symbol = &quot;MITH&quot;, split = 3. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 34: symbol = &quot;MITH&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 34: symbol = &quot;MITH&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 35: symbol = &quot;MITH&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 35: symbol = &quot;MITH&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 36: symbol = &quot;SNT&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 36: symbol = &quot;SNT&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 37: symbol = &quot;SNT&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 37: symbol = &quot;SNT&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 38: symbol = &quot;SNT&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 38: symbol = &quot;SNT&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 39: symbol = &quot;SNT&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 39: symbol = &quot;SNT&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 40: symbol = &quot;SNT&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 40: symbol = &quot;SNT&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 41: symbol = &quot;VET&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 41: symbol = &quot;VET&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 41: symbol = &quot;VET&quot;, split = 1. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 42: symbol = &quot;VET&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 42: symbol = &quot;VET&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 42: symbol = &quot;VET&quot;, split = 2. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 43: symbol = &quot;VET&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 43: symbol = &quot;VET&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 44: symbol = &quot;VET&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 44: symbol = &quot;VET&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 45: symbol = &quot;VET&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 45: symbol = &quot;VET&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 46: symbol = &quot;XEM&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 46: symbol = &quot;XEM&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 47: symbol = &quot;XEM&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 47: symbol = &quot;XEM&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 47: symbol = &quot;XEM&quot;, split = 2. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 48: symbol = &quot;XEM&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 48: symbol = &quot;XEM&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 49: symbol = &quot;XEM&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 49: symbol = &quot;XEM&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 50: symbol = &quot;XEM&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 50: symbol = &quot;XEM&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 50: symbol = &quot;XEM&quot;, split = 5. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 51: symbol = &quot;ZIL&quot;, split = 1. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 51: symbol = &quot;ZIL&quot;, split = 1. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 52: symbol = &quot;ZIL&quot;, split = 2. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 52: symbol = &quot;ZIL&quot;, split = 2. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 53: symbol = &quot;ZIL&quot;, split = 3. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 53: symbol = &quot;ZIL&quot;, split = 3. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 53: symbol = &quot;ZIL&quot;, split = 3. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 54: symbol = &quot;ZIL&quot;, split = 4. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 54: symbol = &quot;ZIL&quot;, split = 4. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m longer object length is not a multiple of shorter object length ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 54: symbol = &quot;ZIL&quot;, split = 4. ## Warning in sae$encoder[[i - 1]]$W[[1]] %*% t(train_x) + sae$encoder[[i - : ## longer object length is not a multiple of shorter object length ## training layer 3 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m There were missing values in resampled performance measures. ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 55: symbol = &quot;ZIL&quot;, split = 5. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning: Problem with `mutate()` input `nnet_model`. ## [34mℹ[39m missing values found in aggregated results ## [34mℹ[39m Input `nnet_model` is `map2(train_data, &quot;dnn&quot;, model_caret)`. ## [34mℹ[39m The error occurred in group 55: symbol = &quot;ZIL&quot;, split = 5. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results ## begin to train sae ...... ## training layer 1 autoencoder ... ## training layer 2 autoencoder ... ## sae has been trained. ## begin to train deep nn ...... ## deep nn has been trained. 5.2.5.2 Gradient Boosting Machines [TODO - Here could also mention using preProcess function to do things like center and scale data ] 5.3 Make Predictions [TODO] … first one example… predict(object = cryptodata_nested$lm_model[[1]], newdata = cryptodata_nested$test_data[[1]], na.action = na.pass) ## 1 2 3 4 5 6 7 8 ## NA NA NA NA NA NA NA NA ## 9 10 11 12 13 14 15 16 ## NA NA NA 17.65148 NA NA NA NA ## 17 18 19 20 21 22 23 24 ## NA NA NA NA NA NA NA NA ## 25 26 27 28 29 30 31 32 ## NA NA NA NA NA NA NA NA ## 33 34 35 36 37 38 39 40 ## NA NA NA NA NA NA NA NA ## 41 42 43 44 45 46 47 48 ## NA NA NA NA NA NA NA 17.67318 ## 49 50 ## 17.67083 17.66513 … now make function to use for map make_predictions &lt;- function(model, test){ predict(object = model, newdata = test, na.action = na.pass) } And use map2() to use it to make predictions and create new columns for both the test data and the holdout: cryptodata_nested &lt;- mutate(cryptodata_nested, lm_test_predictions = map2(lm_model, test_data, make_predictions), lm_holdout_predictions = map2(lm_model, holdout_data, make_predictions)) ## Warning: Problem with `mutate()` input `lm_test_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_test_predictions` is `map2(lm_model, test_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 2: symbol = &quot;ARPA&quot;, split = 2. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_test_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_test_predictions` is `map2(lm_model, test_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 19: symbol = &quot;FDZ&quot;, split = 4. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_test_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_test_predictions` is `map2(lm_model, test_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_test_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_test_predictions` is `map2(lm_model, test_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 24: symbol = &quot;LINK&quot;, split = 4. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_test_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_test_predictions` is `map2(lm_model, test_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 45: symbol = &quot;VET&quot;, split = 5. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_holdout_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_holdout_predictions` is `map2(lm_model, holdout_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 2: symbol = &quot;ARPA&quot;, split = 2. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_holdout_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_holdout_predictions` is `map2(lm_model, holdout_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 19: symbol = &quot;FDZ&quot;, split = 4. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_holdout_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_holdout_predictions` is `map2(lm_model, holdout_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 20: symbol = &quot;FDZ&quot;, split = 5. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_holdout_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_holdout_predictions` is `map2(lm_model, holdout_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 24: symbol = &quot;LINK&quot;, split = 4. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading ## Warning: Problem with `mutate()` input `lm_holdout_predictions`. ## [34mℹ[39m prediction from a rank-deficient fit may be misleading ## [34mℹ[39m Input `lm_holdout_predictions` is `map2(lm_model, holdout_data, make_predictions)`. ## [34mℹ[39m The error occurred in group 45: symbol = &quot;VET&quot;, split = 5. ## Warning in predict.lm(modelFit, newdata): prediction from a rank-deficient fit ## may be misleading We can view the results: select(cryptodata_nested, lm_test_predictions, lm_holdout_predictions) ## Adding missing grouping variables: `symbol`, `split` ## [90m# A tibble: 55 x 4[39m ## [90m# Groups: symbol, split [55][39m ## symbol split lm_test_predictions lm_holdout_predictions ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m [3m[90m&lt;list&gt;[39m[23m ## [90m 1[39m LINK 1 [90m&lt;dbl [50]&gt;[39m [90m&lt;dbl [52]&gt;[39m ## [90m 2[39m VET 1 [90m&lt;dbl [70]&gt;[39m [90m&lt;dbl [71]&gt;[39m ## [90m 3[39m ARPA 1 [90m&lt;dbl [29]&gt;[39m [90m&lt;dbl [30]&gt;[39m ## [90m 4[39m SNT 1 [90m&lt;dbl [29]&gt;[39m [90m&lt;dbl [30]&gt;[39m ## [90m 5[39m ZIL 1 [90m&lt;dbl [44]&gt;[39m [90m&lt;dbl [44]&gt;[39m ## [90m 6[39m MCO 1 [90m&lt;dbl [29]&gt;[39m [90m&lt;dbl [30]&gt;[39m ## [90m 7[39m XEM 1 [90m&lt;dbl [69]&gt;[39m [90m&lt;dbl [72]&gt;[39m ## [90m 8[39m MITH 1 [90m&lt;dbl [29]&gt;[39m [90m&lt;dbl [29]&gt;[39m ## [90m 9[39m COMP 1 [90m&lt;dbl [29]&gt;[39m [90m&lt;dbl [29]&gt;[39m ## [90m10[39m FDZ 1 [90m&lt;dbl [51]&gt;[39m [90m&lt;dbl [54]&gt;[39m ## [90m# … with 45 more rows[39m Now we can do the same for the rest of the models: cryptodata_nested &lt;- mutate(cryptodata_nested, # XGBoost: xgb_test_predictions = map2(xgb_model, test_data, make_predictions), xgb_holdout_predictions = map2(xgb_model, holdout_data, make_predictions), # XGBoost Trees: xgbTree_test_predictions = map2(xgbTree_model, test_data, make_predictions), xgbTree_holdout_predictions = map2(xgbTree_model, holdout_data, make_predictions), # Neural Network: nnet_test_predictions = map2(nnet_model, test_data, make_predictions), nnet_holdout_predictions = map2(nnet_model, holdout_data, make_predictions)) Done with the parallel processing now: stopCluster(cl) 5.4 Traditional Timeseries "],["evaluate-model-performance.html", "Section - 6 Evaluate Model Performance 6.1 Summarizing models 6.2 Visualize Results", " Section - 6 Evaluate Model Performance 6.1 Summarizing models Example for one model: postResample(pred = cryptodata_nested$lm_test_predictions[[1]], obs = cryptodata_nested$test_data[[1]]$target_price_24h) ## RMSE Rsquared MAE ## 17.6416197 0.9493526 17.6416174 We can extract the first element to return the RMSE metric, and the second element for the R Squared (R^2) metric: print(paste(&#39;Now showing RMSE example:&#39;, postResample(pred = cryptodata_nested$lm_test_predictions[[1]], obs = cryptodata_nested$test_data[[1]]$target_price_24h)[[1]])) ## [1] &quot;Now showing RMSE example: 17.641619726004&quot; print(paste(&#39;Now showing R Squared example:&#39;, postResample(pred = cryptodata_nested$lm_test_predictions[[1]], obs = cryptodata_nested$test_data[[1]]$target_price_24h)[[2]])) ## [1] &quot;Now showing R Squared example: 0.94935262688022&quot; 6.1.1 Adjust RMSE [TODO - NEED TO MAKE SURE RMSE IS STANDARDIZED HERE!] Because cryptocurrencies can vary dramatically in their prices with some trading in the tens of thousands of dollars and others trading for less than a cent, we need to make sure to standardize the RMSE columns to provide a fair comparison for the metric. Therefore, before using the postResample() function, let’s convert both the predictions and the target to be the % change in price over the 24 hour period, rather than the change in price ($). 6.1.1.1 Predictions Adjustment First we will adjust the predictions to instead of being predictions for the price in dollars, will be % change relative to the previous price. calculate_percent_change_preds &lt;- function(train, test_predictions){ ((lag(tail(train,1)$price_usd, 1) - tail(train,1)$price_usd) / abs(tail(train,1)$price_usd))*100 } Overwrite the old predictions with the predictions adjusted as a percentage now: First create a new column with the last price from the the train data: # add here Then use that to calculate the first % change, then can calculate the rest for test set by doing ((lag(price, 1) - price / abs(price))*100… KEEP GOING 6.1.1.2 Actual Results Adjustment Now do the same thing to the target variable before we calculate the error metrics: calculate_percent_change_actual &lt;- function(train, test_predictions){ ((lag(tail(train,1)$price_usd, 1) - tail(train,1)$price_usd) / abs(tail(train,1)$price_usd))*100 } Overwrite the old predictions with the predictions adjusted as a 6.1.2 Calculate RMSE Now make a function to get the RMSE metric for all models: evaluate_preds_rmse &lt;- function(predictions, test_data){ postResample(pred = predictions, obs = test_data$target_price_24h)[[1]] } Now we can use map2() to use it to get the RMSE metric for both the test data and the holdout: cryptodata_nested &lt;- mutate(cryptodata_nested, lm_rmse = unlist(ifelse(split &lt; 5, map2(lm_test_predictions, test_data, evaluate_preds_rmse), map2(lm_holdout_predictions, holdout_data, evaluate_preds_rmse)))) Look at the results: select(cryptodata_nested, lm_rmse) ## Adding missing grouping variables: `symbol`, `split` ## [90m# A tibble: 55 x 3[39m ## [90m# Groups: symbol, split [55][39m ## symbol split lm_rmse ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m LINK 1 17.6 ## [90m 2[39m VET 1 0.019[4m3[24m ## [90m 3[39m ARPA 1 0.096[4m0[24m ## [90m 4[39m SNT 1 [4m1[24m[4m1[24m789. ## [90m 5[39m ZIL 1 7.44 ## [90m 6[39m MCO 1 254. ## [90m 7[39m XEM 1 19.4 ## [90m 8[39m MITH 1 0.589 ## [90m 9[39m COMP 1 131. ## [90m10[39m FDZ 1 23.9 ## [90m# … with 45 more rows[39m 6.1.3 Calculate R^2 Now we can do the same for the R Squared metric: evaluate_preds_rsq &lt;- function(predictions, test_data){ postResample(pred = predictions, obs = test_data$target_price_24h)[[2]] } cryptodata_nested &lt;- mutate(cryptodata_nested, lm_rsq = unlist(ifelse(split &lt; 5, map2(lm_test_predictions, test_data, evaluate_preds_rsq), map2(lm_holdout_predictions, holdout_data, evaluate_preds_rsq)))) And now we can do the same for all the other models cryptodata_nested &lt;- mutate(cryptodata_nested, # XGBoost - RMSE xgb_rmse = unlist(ifelse(split &lt; 5, map2(xgb_test_predictions, test_data, evaluate_preds_rmse), map2(xgb_holdout_predictions, holdout_data,evaluate_preds_rmse))), # XGBoost - R^2 xgb_rsq = unlist(ifelse(split &lt; 5, map2(xgb_test_predictions, test_data, evaluate_preds_rsq), map2(xgb_holdout_predictions, holdout_data, evaluate_preds_rsq))), # XGBoost Trees - RMSE xgbTree_rmse = unlist(ifelse(split &lt; 5, map2(xgbTree_test_predictions, test_data, evaluate_preds_rmse), map2(xgbTree_holdout_predictions, holdout_data, evaluate_preds_rmse))), # XGBoost Trees - R^2 xgbTree_rsq = unlist(ifelse(split &lt; 5, map2(xgbTree_test_predictions, test_data, evaluate_preds_rsq), map2(xgbTree_holdout_predictions, holdout_data, evaluate_preds_rsq))), # Neural Network - RMSE nnet_rmse = unlist(ifelse(split &lt; 5, map2(nnet_test_predictions, test_data, evaluate_preds_rmse), map2(nnet_holdout_predictions, holdout_data, evaluate_preds_rmse))), # Neural Network - R^2 nnet_rsq = unlist(ifelse(split &lt; 5, map2(nnet_test_predictions, test_data, evaluate_preds_rsq), map2(nnet_holdout_predictions, holdout_data, evaluate_preds_rsq)))) Now we have RMSE values for every model created for every cryptocurrency and split of the data: rmse_scores &lt;- select(cryptodata_nested, lm_rmse, xgb_rmse, xgbTree_rmse, nnet_rmse) ## Adding missing grouping variables: `symbol`, `split` # Show RMSE scores rmse_scores ## [90m# A tibble: 55 x 6[39m ## [90m# Groups: symbol, split [55][39m ## symbol split lm_rmse xgb_rmse xgbTree_rmse nnet_rmse ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m LINK 1 17.6 17.9 18.4 17.2 ## [90m 2[39m VET 1 0.019[4m3[24m [31mNA[39m [31mNA[39m 0.022[4m8[24m ## [90m 3[39m ARPA 1 0.096[4m0[24m 0.027[4m4[24m 0.024[4m7[24m 0.008[4m6[24m[4m1[24m ## [90m 4[39m SNT 1 [4m1[24m[4m1[24m789. [31mNA[39m [31mNA[39m [4m1[24m[4m1[24m866. ## [90m 5[39m ZIL 1 7.44 7.12 7.12 7.45 ## [90m 6[39m MCO 1 254. [31mNA[39m [31mNA[39m 74.4 ## [90m 7[39m XEM 1 19.4 [31mNA[39m [31mNA[39m 19.4 ## [90m 8[39m MITH 1 0.589 2.29 2.29 2.37 ## [90m 9[39m COMP 1 131. 135. 135. 154. ## [90m10[39m FDZ 1 23.9 23.9 23.9 23.9 ## [90m# … with 45 more rows[39m And the R Squared values: rsq_scores &lt;- select(cryptodata_nested, lm_rsq, xgb_rsq, xgbTree_rsq, nnet_rsq) ## Adding missing grouping variables: `symbol`, `split` # Show R^2 scores rsq_scores ## [90m# A tibble: 55 x 6[39m ## [90m# Groups: symbol, split [55][39m ## symbol split lm_rsq xgb_rsq xgbTree_rsq nnet_rsq ## [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m ## [90m 1[39m LINK 1 0.949 0.704 0.167 [31mNA[39m ## [90m 2[39m VET 1 0.203 0.109 0.033[4m7[24m [31mNA[39m ## [90m 3[39m ARPA 1 0.682 0.009[4m5[24m[4m4[24m 0.017[4m8[24m 0.698 ## [90m 4[39m SNT 1 0.060[4m2[24m 0.026[4m8[24m 0.094[4m3[24m [31mNA[39m ## [90m 5[39m ZIL 1 0.591 0.991 0.964 [31mNA[39m ## [90m 6[39m MCO 1 1.00 0.126 0.138 [31mNA[39m ## [90m 7[39m XEM 1 0.320 0.012[4m6[24m 0.027[4m7[24m [31mNA[39m ## [90m 8[39m MITH 1 1.00 0.142 0.908 0.448 ## [90m 9[39m COMP 1 0.625 0.203 0.310 [31mNA[39m ## [90m10[39m FDZ 1 0.901 0.636 [31mNA[39m [31mNA[39m ## [90m# … with 45 more rows[39m 6.1.4 New Section Now for each model we will create a new column giving the average RMSE and R^2 for the 4 cross-validation split, and a separate column to give the score for the holdout. rmse_scores &lt;- mutate(cryptodata_nested, lm = mean(lm_rmse, na.rm = T), xgb = mean(xgb_rmse, na.rm = T), xgbTree = mean(xgbTree_rmse, na.rm = T), nnet = mean(nnet_rmse, na.rm = T)) Now we can use the gather() function to summarize the columns as rows: rmse_scores &lt;- unique(gather(select(rmse_scores, lm:nnet), &#39;model&#39;, &#39;rmse&#39;, c(-symbol,-split))) ## Adding missing grouping variables: `symbol`, `split` Now the same for the R^2 rsq_scores &lt;- mutate(cryptodata_nested, lm = mean(lm_rsq, na.rm = T), xgb = mean(xgb_rsq, na.rm = T), xgbTree = mean(xgbTree_rsq, na.rm = T), nnet = mean(nnet_rsq, na.rm = T)) Now we can use the gather() function to summarize the columns as rows: rsq_scores &lt;- unique(gather(select(rsq_scores, lm:nnet), &#39;model&#39;, &#39;rsq&#39;, c(-symbol,-split))) ## Adding missing grouping variables: `symbol`, `split` 6.2 Visualize Results 6.2.1 RMSE Visualization Now we can take the same tools we learned in the Visualization section from earlier and visualize the results of the models. ggplot(rmse_scores, aes(x=split, y=rmse, color = model)) + geom_boxplot() + geom_point() + facet_wrap(~split) ## Warning: Removed 48 rows containing non-finite values (stat_boxplot). ## Warning: Removed 48 rows containing missing values (geom_point). 6.2.2 Both 6.2.2.1 Join Datasets First join the two plot_scores &lt;- merge(rmse_scores, rsq_scores) 6.2.2.2 Plot Results ggplot(plot_scores, aes(x=rsq, y=rmse, color = model)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## Warning: Removed 105 rows containing non-finite values (stat_smooth). ## Warning: Removed 105 rows containing missing values (geom_point). ggplot(plot_scores, aes(x=rsq, y=rmse, color = model)) + geom_boxplot() + geom_point() + facet_wrap(~split) ## Warning: Removed 67 rows containing missing values (stat_boxplot). ## Warning: Removed 38 rows containing non-finite values (stat_boxplot). ## Warning: Removed 105 rows containing missing values (geom_point). Now by the cryptocurrency ggplot(plot_scores, aes(x=rsq, y=rmse, color = model)) + geom_point() + geom_smooth() + facet_wrap(~symbol) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## Warning: Removed 105 rows containing non-finite values (stat_smooth). ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at -0.00094899 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.65959 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.0093007 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## -0.00094899 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.65959 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.0093007 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.021864 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.51896 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.096386 ## Warning in sqrt(sum.squares/one.delta): NaNs produced ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.021864 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.51896 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.096386 ## Warning in stats::qt(level/2 + 0.5, pred$df): NaNs produced ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.0047519 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.0070283 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.92138 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.0047519 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.0070283 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.92138 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at -0.00096304 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.018753 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.97454 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## -0.00096304 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.018753 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.97454 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.10022 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.37809 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.27685 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.10022 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.37809 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.27685 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.069299 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.55521 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.038499 ## Warning in sqrt(sum.squares/one.delta): NaNs produced ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.069299 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.55521 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.038499 ## Warning in stats::qt(level/2 + 0.5, pred$df): NaNs produced ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.19968 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.029769 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.44005 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.19968 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.029769 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.44005 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.02436 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.21572 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.40187 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : Chernobyl! trL&gt;n 5 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : Chernobyl! trL&gt;n 5 ## Warning in sqrt(sum.squares/one.delta): NaNs produced ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.02436 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.21572 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.40187 ## Warning in stats::qt(level/2 + 0.5, pred$df): NaNs produced ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.18122 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.057115 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.4444 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.18122 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.057115 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.4444 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.017467 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.32168 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.3967 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.017467 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.32168 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.3967 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.10459 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.072718 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.071009 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.10459 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.072718 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.071009 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : at 0.51823 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : radius 8.5547e-07 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : all data on boundary of neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.51823 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.00092492 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 1 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : at 0.70506 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : radius 8.5547e-07 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : all data on boundary of neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 8.5547e-07 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : zero-width neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : zero-width neighborhood. make span bigger ## Warning: Computation failed in `stat_smooth()`: ## NA/NaN/Inf in foreign function call (arg 5) ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at -0.0020618 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.98471 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.00049883 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## -0.0020618 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.98471 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.00049883 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.34026 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.34314 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.1408 ## Warning in sqrt(sum.squares/one.delta): NaNs produced ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.34026 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.34314 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.1408 ## Warning in stats::qt(level/2 + 0.5, pred$df): NaNs produced ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.22029 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.45043 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.20946 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.22029 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.45043 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.20946 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.027725 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.72273 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.064708 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.027725 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.72273 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.064708 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.44648 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.25628 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.00043106 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.44648 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.25628 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.00043106 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.14113 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.054022 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.045454 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.14113 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.054022 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.045454 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.061985 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.55187 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.089019 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.061985 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.55187 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.089019 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.00071214 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.05952 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.5488 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.00071214 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.05952 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.5488 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : at 0.15523 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : radius 6.5776e-06 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : all data on boundary of neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.15523 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.0025647 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 1 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : at 0.6733 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : radius 6.5776e-06 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : all data on boundary of neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 6.5776e-06 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : zero-width neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : zero-width neighborhood. make span bigger ## Warning: Computation failed in `stat_smooth()`: ## NA/NaN/Inf in foreign function call (arg 5) ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.012515 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.42436 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.32267 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : Chernobyl! trL&gt;n 5 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : Chernobyl! trL&gt;n 5 ## Warning in sqrt(sum.squares/one.delta): NaNs produced ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.012515 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.42436 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.32267 ## Warning in stats::qt(level/2 + 0.5, pred$df): NaNs produced ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : at -0.0020675 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : radius 2.4848e-05 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : all data on boundary of neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at -0.0020675 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.0049848 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 1 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : at 1.0049 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : radius 2.4848e-05 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : all data on boundary of neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 2.4848e-05 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : zero-width neighborhood. make span bigger ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : zero-width neighborhood. make span bigger ## Warning: Computation failed in `stat_smooth()`: ## NA/NaN/Inf in foreign function call (arg 5) ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.0052511 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.31482 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.63843 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.0052511 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.31482 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.63843 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.090708 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.5579 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.12249 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.090708 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.5579 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.12249 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.35323 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.097547 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.2948 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.35323 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.097547 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.2948 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : span too small. fewer data values than degrees of freedom. ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : pseudoinverse used at 0.12715 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : neighborhood radius 0.31328 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : reciprocal condition number 0 ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric = ## parametric, : There are other near singularities as well. 0.2789 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer ## data values than degrees of freedom. ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at ## 0.12715 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius ## 0.31328 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition ## number 0 ## Warning in predLoess(object$y, object$x, newx = if ## (is.null(newdata)) object$x else if (is.data.frame(newdata)) ## as.matrix(model.frame(delete.response(terms(object)), : There are other near ## singularities as well. 0.2789 ## Warning: Removed 105 rows containing missing values (geom_point). ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning - ## Inf 6.2.3 Results by the Cryptocurrency knitr::include_app(&#39;https://predictcrypto.shinyapps.io/tutorial_latest_model_summary/&#39;, height = &#39;600px&#39;) The app shown above also has a button to Show Code. If you were to copy and paste that code into an RStudio session on your computer into a file with the .Rmd file extension and you then Knit the file, the same exact app should show up on your computer, no logins or setup outside of the packages required for the code to run; RStudio should automatically prompt you to install packages that are not currently installed on your computer. [TODO - HERE ALSO REMEMBER TO LOG MLFLOW METRICS AND WRITE THE SAME INFO TO THE DB] "],["time-series.html", "Section - 7 Time Series", " Section - 7 Time Series Add here "],["explain-predictions.html", "Section - 8 Explain Predictions", " Section - 8 Explain Predictions # remove after test! print(&#39;got here&#39;) ## [1] &quot;got here&quot; "],["considerations.html", "Section - 9 Considerations 9.1 Session Information", " Section - 9 Considerations What we have outlined here is a supervised machine learning problem and a practical possible approach to the problem, but the results contained in this document would not translate to real-world results. This tutorial is not meant to show anyone how to trade on the cryptocurrency markets, but rather encourage people to apply these tools to their own data problems, and that is the reason the tutorial stops here (also because we like not getting sued). We stop here before dealing with many difficult execution problems, including but not exclusive to: Finding a trading methodology that makes sense. There are lots of decisions to be made, market or limit orders? Coming up with a good trade execution plan that works consistently is not as easy. …Keep outlining the issues outlined by Chandler, especially relating to low market cap cryptocurrencies 9.1 Session Information Below is information relating to the specific R session that was run. If you are unable to reproduce these steps, find the correct version of the tools to install below: sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] parallel stats graphics grDevices utils datasets methods ## [8] base ## ## other attached packages: ## [1] magick_2.5.0 av_0.5.1 ggTimeSeries_1.0.1 ggthemes_4.2.0 ## [5] gbm_2.1.8 xgboost_1.0.0.2 gifski_0.8.6 tictoc_1.0 ## [9] gganimate_1.0.5 anytime_0.3.7 caret_6.0-86 lattice_0.20-38 ## [13] DT_0.15 doParallel_1.0.15 iterators_1.0.12 foreach_1.5.0 ## [17] tsibble_0.9.2 skimr_2.1 forcats_0.5.0 stringr_1.4.0 ## [21] dplyr_1.0.2 purrr_0.3.4 readr_1.3.1 tidyr_1.1.1 ## [25] tibble_3.0.4 ggplot2_3.3.2 tidyverse_1.3.0 pins_0.4.0 ## [29] pacman_0.5.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.1 class_7.3-15 ## [4] base64enc_0.1-3 fs_1.4.1 rstudioapi_0.11 ## [7] farver_2.0.3 prodlim_2019.11.13 fansi_0.4.1 ## [10] lubridate_1.7.8 xml2_1.3.1 codetools_0.2-16 ## [13] splines_4.0.3 knitr_1.30 jsonlite_1.7.1 ## [16] pROC_1.16.2 broom_0.7.2 dbplyr_1.4.2 ## [19] shiny_1.5.0 compiler_4.0.3 httr_1.4.2 ## [22] backports_1.1.6 assertthat_0.2.1 Matrix_1.2-18 ## [25] fastmap_1.0.1 cli_2.0.2 later_1.0.0 ## [28] tweenr_1.0.1 htmltools_0.5.0 prettyunits_1.1.1 ## [31] tools_4.0.3 gtable_0.3.0 glue_1.4.1 ## [34] reshape2_1.4.3 rappdirs_0.3.1 Rcpp_1.0.4.6 ## [37] cellranger_1.1.0 vctrs_0.3.2 nlme_3.1-144 ## [40] crosstalk_1.1.0.1 timeDate_3043.102 gower_0.2.1 ## [43] xfun_0.18 rvest_0.3.5 miniUI_0.1.1.1 ## [46] mime_0.9 lifecycle_0.2.0 MASS_7.3-51.5 ## [49] scales_1.1.1 ipred_0.9-9 hms_0.5.3 ## [52] promises_1.1.0 curl_4.3 yaml_2.2.1 ## [55] rpart_4.1-15 stringi_1.4.6 highr_0.8 ## [58] deepnet_0.2 filelock_1.0.2 manipulateWidget_0.10.1 ## [61] lava_1.6.7 repr_1.1.0 rlang_0.4.7 ## [64] pkgconfig_2.0.3 evaluate_0.14 labeling_0.3 ## [67] recipes_0.1.14 htmlwidgets_1.5.1 tidyselect_1.1.0 ## [70] plyr_1.8.6 magrittr_1.5 bookdown_0.21 ## [73] R6_2.4.1 generics_0.0.2 DBI_1.1.0 ## [76] mgcv_1.8-31 pillar_1.4.4 haven_2.2.0 ## [79] withr_2.3.0 survival_3.1-8 nnet_7.3-12 ## [82] modelr_0.1.6 crayon_1.3.4 utf8_1.1.4 ## [85] rmarkdown_2.5 emo_0.0.0.9000 progress_1.2.2 ## [88] grid_4.0.3 readxl_1.3.1 data.table_1.12.8 ## [91] ModelMetrics_1.2.2.2 webshot_0.5.2 reprex_0.3.0 ## [94] digest_0.6.25 xtable_1.8-4 httpuv_1.5.2 ## [97] stats4_4.0.3 munsell_0.5.0 "],["archive.html", "Section - 10 Archive 10.1 May 2020", " Section - 10 Archive Below is an archive of this same document from different dates: 10.1 May 2020 May 23, 2020 - Morning May 22, 2020 - Morning May 21, 2020 - Morning May 20, 2020 - Morning May 19, 2020 - Morning May 18, 2020 - Morning "],["references.html", "Section - 11 References 11.1 Resources Used 11.2 Packages used and cited", " Section - 11 References The bookdown package [@R-bookdown] was used to produce this document, which was built on top of R Markdown and knitr [@xie2015]. knitr::write_bib(c(.packages()), &quot;packages.bib&quot;) 11.1 Resources Used 11.1.1 Visualization Section https://www.rayshader.com/ https://github.com/yutannihilation/gghighlight https://github.com/njtierney/rstudioconf20/blob/master/slides/index.Rmd … add rest here 11.1.2 Time Series Section https://stackoverflow.com/questions/42820696/using-prophet-package-to-predict-by-group-in-dataframe-in-r … add rest here 11.2 Packages used and cited "]]
